# Configuración para Deep Research con API local y DuckDuckGo

# Configuración del modelo local (localhost:1234)
# Usar el formato: openai:http://localhost:1234/v1
RESEARCH_MODEL=openai:http://localhost:1234/v1
SUMMARIZATION_MODEL=openai:http://localhost:1234/v1
COMPRESSION_MODEL=openai:http://localhost:1234/v1
FINAL_REPORT_MODEL=openai:http://localhost:1234/v1

# API Key para el modelo local - usar cualquier valor ya que tu API acepta cualquier clave
OPENAI_API_KEY=test-key

# Configuración de búsqueda - usar DuckDuckGo en lugar de Tavily
SEARCH_API=duckduckgo

# Configuración de tokens
RESEARCH_MODEL_MAX_TOKENS=10000
SUMMARIZATION_MODEL_MAX_TOKENS=8192
COMPRESSION_MODEL_MAX_TOKENS=8192
FINAL_REPORT_MODEL_MAX_TOKENS=10000

# Configuración de investigación
MAX_CONCURRENT_RESEARCH_UNITS=3
MAX_RESEARCHER_ITERATIONS=4
MAX_REACT_TOOL_CALLS=8
MAX_STRUCTURED_OUTPUT_RETRIES=3

# Configuración de contenido
MAX_CONTENT_LENGTH=50000

# Configuración de clarificación
ALLOW_CLARIFICATION=true

# Configuración MCP (opcional) - dejar vacío para deshabilitar
# MCP_CONFIG=
# MCP_PROMPT=
